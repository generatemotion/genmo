<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>vqvae算法 | GenMo</title>
    <meta name="generator" content="VuePress 1.9.10">
    
    <meta name="description" content="Generate Motion">
    
    <link rel="preload" href="/genmo/assets/css/0.styles.84f978c2.css" as="style"><link rel="preload" href="/genmo/assets/js/app.26c693c1.js" as="script"><link rel="preload" href="/genmo/assets/js/2.778bb4ad.js" as="script"><link rel="preload" href="/genmo/assets/js/1.50b457b8.js" as="script"><link rel="preload" href="/genmo/assets/js/69.9e67f88e.js" as="script"><link rel="prefetch" href="/genmo/assets/js/10.325b9f09.js"><link rel="prefetch" href="/genmo/assets/js/11.c62b6b34.js"><link rel="prefetch" href="/genmo/assets/js/12.ecdb524b.js"><link rel="prefetch" href="/genmo/assets/js/13.3f3f6a36.js"><link rel="prefetch" href="/genmo/assets/js/14.eb7a3d07.js"><link rel="prefetch" href="/genmo/assets/js/15.114dfd5c.js"><link rel="prefetch" href="/genmo/assets/js/16.85253907.js"><link rel="prefetch" href="/genmo/assets/js/17.c2838453.js"><link rel="prefetch" href="/genmo/assets/js/18.3256f17f.js"><link rel="prefetch" href="/genmo/assets/js/19.d8afd0ae.js"><link rel="prefetch" href="/genmo/assets/js/20.10e47ab9.js"><link rel="prefetch" href="/genmo/assets/js/21.33b300c9.js"><link rel="prefetch" href="/genmo/assets/js/22.325f97d5.js"><link rel="prefetch" href="/genmo/assets/js/23.a51c925e.js"><link rel="prefetch" href="/genmo/assets/js/24.22712080.js"><link rel="prefetch" href="/genmo/assets/js/25.e8554233.js"><link rel="prefetch" href="/genmo/assets/js/26.5859999a.js"><link rel="prefetch" href="/genmo/assets/js/27.64aaa112.js"><link rel="prefetch" href="/genmo/assets/js/28.74e53adc.js"><link rel="prefetch" href="/genmo/assets/js/29.55f636cd.js"><link rel="prefetch" href="/genmo/assets/js/3.af33e5d6.js"><link rel="prefetch" href="/genmo/assets/js/30.842ab42d.js"><link rel="prefetch" href="/genmo/assets/js/31.0badfc85.js"><link rel="prefetch" href="/genmo/assets/js/32.931dc4b4.js"><link rel="prefetch" href="/genmo/assets/js/33.f0ea27b3.js"><link rel="prefetch" href="/genmo/assets/js/34.3aa0c414.js"><link rel="prefetch" href="/genmo/assets/js/35.8dadf405.js"><link rel="prefetch" href="/genmo/assets/js/36.989f54d3.js"><link rel="prefetch" href="/genmo/assets/js/37.46cbd986.js"><link rel="prefetch" href="/genmo/assets/js/38.97296340.js"><link rel="prefetch" href="/genmo/assets/js/39.5962b011.js"><link rel="prefetch" href="/genmo/assets/js/4.45665f8a.js"><link rel="prefetch" href="/genmo/assets/js/40.5f3de182.js"><link rel="prefetch" href="/genmo/assets/js/41.d2a9613d.js"><link rel="prefetch" href="/genmo/assets/js/42.a698d78e.js"><link rel="prefetch" href="/genmo/assets/js/43.f6af9a36.js"><link rel="prefetch" href="/genmo/assets/js/44.74fed02e.js"><link rel="prefetch" href="/genmo/assets/js/45.39c81079.js"><link rel="prefetch" href="/genmo/assets/js/46.e41a75b4.js"><link rel="prefetch" href="/genmo/assets/js/47.e6fc9c03.js"><link rel="prefetch" href="/genmo/assets/js/48.8f6cc604.js"><link rel="prefetch" href="/genmo/assets/js/49.a5ad7ee5.js"><link rel="prefetch" href="/genmo/assets/js/5.7098d77a.js"><link rel="prefetch" href="/genmo/assets/js/50.1881828f.js"><link rel="prefetch" href="/genmo/assets/js/51.ce4cd92a.js"><link rel="prefetch" href="/genmo/assets/js/52.adcabbc6.js"><link rel="prefetch" href="/genmo/assets/js/53.f2f86279.js"><link rel="prefetch" href="/genmo/assets/js/54.36a50147.js"><link rel="prefetch" href="/genmo/assets/js/55.e094f2d2.js"><link rel="prefetch" href="/genmo/assets/js/56.bb877cbe.js"><link rel="prefetch" href="/genmo/assets/js/57.c54b788e.js"><link rel="prefetch" href="/genmo/assets/js/58.5ef6e07e.js"><link rel="prefetch" href="/genmo/assets/js/59.48f41fd9.js"><link rel="prefetch" href="/genmo/assets/js/6.0c0a0f39.js"><link rel="prefetch" href="/genmo/assets/js/60.4e7540b6.js"><link rel="prefetch" href="/genmo/assets/js/61.8f461756.js"><link rel="prefetch" href="/genmo/assets/js/62.6219f95f.js"><link rel="prefetch" href="/genmo/assets/js/63.0447b50c.js"><link rel="prefetch" href="/genmo/assets/js/64.72f54285.js"><link rel="prefetch" href="/genmo/assets/js/65.1a00a05f.js"><link rel="prefetch" href="/genmo/assets/js/66.c9a0a3cb.js"><link rel="prefetch" href="/genmo/assets/js/67.5a16509d.js"><link rel="prefetch" href="/genmo/assets/js/68.480a63ec.js"><link rel="prefetch" href="/genmo/assets/js/7.6a854e57.js"><link rel="prefetch" href="/genmo/assets/js/70.b035d654.js"><link rel="prefetch" href="/genmo/assets/js/71.06314f6b.js"><link rel="prefetch" href="/genmo/assets/js/72.0d9dec58.js"><link rel="prefetch" href="/genmo/assets/js/73.732392b9.js"><link rel="prefetch" href="/genmo/assets/js/74.d4876ba2.js"><link rel="prefetch" href="/genmo/assets/js/75.79eb6294.js"><link rel="prefetch" href="/genmo/assets/js/76.6a0cf2e1.js"><link rel="prefetch" href="/genmo/assets/js/77.51d58148.js"><link rel="prefetch" href="/genmo/assets/js/78.90b53af6.js"><link rel="prefetch" href="/genmo/assets/js/79.b2c388b9.js"><link rel="prefetch" href="/genmo/assets/js/80.6652051c.js"><link rel="prefetch" href="/genmo/assets/js/81.e9a08b1d.js"><link rel="prefetch" href="/genmo/assets/js/82.ab554a28.js"><link rel="prefetch" href="/genmo/assets/js/83.d195d64f.js"><link rel="prefetch" href="/genmo/assets/js/84.640f2c5d.js"><link rel="prefetch" href="/genmo/assets/js/vendors~docsearch.5e19b665.js">
    <link rel="stylesheet" href="/genmo/assets/css/0.styles.84f978c2.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/genmo/" class="home-link router-link-active"><img src="/genmo/logo3.png" alt="GenMo" class="logo"> <span class="site-name can-hide">GenMo</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/genmo/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/genmo/guide.html" class="nav-link">
  指南
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="深入掌握深度生成技术" class="dropdown-title"><span class="title">AIGC学习</span> <span class="arrow down"></span></button> <button type="button" aria-label="深入掌握深度生成技术" class="mobile-dropdown-title"><span class="title">AIGC学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/genmo/dm/" class="nav-link">
  扩散模型
</a></li><li class="dropdown-item"><!----> <a href="/genmo/osp/" class="nav-link">
  开源项目
</a></li><li class="dropdown-item"><!----> <a href="/genmo/hf/" class="nav-link">
  HF学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/tvm/" class="nav-link">
  TVM学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/tinyml/" class="nav-link">
  TinyML学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/t2m/" class="nav-link router-link-active">
  动作生成学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/bpy/" class="nav-link">
  BPY学习
</a></li></ul></div></div><div class="nav-item"><a href="/genmo/handon/" class="nav-link">
  实战
</a></div><div class="nav-item"><a href="/genmo/about.html" class="nav-link">
  关于
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/genmo/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/genmo/guide.html" class="nav-link">
  指南
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="深入掌握深度生成技术" class="dropdown-title"><span class="title">AIGC学习</span> <span class="arrow down"></span></button> <button type="button" aria-label="深入掌握深度生成技术" class="mobile-dropdown-title"><span class="title">AIGC学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/genmo/dm/" class="nav-link">
  扩散模型
</a></li><li class="dropdown-item"><!----> <a href="/genmo/osp/" class="nav-link">
  开源项目
</a></li><li class="dropdown-item"><!----> <a href="/genmo/hf/" class="nav-link">
  HF学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/tvm/" class="nav-link">
  TVM学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/tinyml/" class="nav-link">
  TinyML学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/t2m/" class="nav-link router-link-active">
  动作生成学习
</a></li><li class="dropdown-item"><!----> <a href="/genmo/bpy/" class="nav-link">
  BPY学习
</a></li></ul></div></div><div class="nav-item"><a href="/genmo/handon/" class="nav-link">
  实战
</a></div><div class="nav-item"><a href="/genmo/about.html" class="nav-link">
  关于
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/genmo/t2m/" class="sidebar-heading clickable router-link-active open"><span>基础</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/genmo/t2m/bvh.html" class="sidebar-link">BVH解释</a></li><li><a href="/genmo/t2m/smpl.html" class="sidebar-link">smpl</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/genmo/t2m/alg" class="sidebar-heading clickable router-link-active"><span>算法</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/genmo/t2m/alg/vq.html" class="sidebar-link">向量量化</a></li><li><a href="/genmo/t2m/alg/motionclip.html" class="sidebar-link">motionclip</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="vqvae算法"><a href="#vqvae算法" class="header-anchor">#</a> vqvae算法</h1> <p>VQ-VAE（Vector Quantised Variational AutoEncoder，矢量量化变分自动编码）是【1】提出的一种离散化VAE方案，近来【2】应用VQ-VAE得到了媲美于BigGan的生成模型。由此可见， VQ-VAE 有着强大的潜力，且【1】和【2】皆为DeepMind的作品，让我们通过代码来认识它，学习它。</p> <h2 id="简介"><a href="#简介" class="header-anchor">#</a> 简介</h2> <p>VQ-VAE属于VAE范畴，它有着与一般VAE都有的Encoder、code（编码）和Decoder，而不同之处在于其code并不是由Encoder直接输出得到，而是经过了一个矢量量化后才得到的，其结构图如下：
<img src="images/t2m/vqvae1.png" alt="">
图1 VQ-VAE结构图
<img src="images/t2m/vqvae2.png" alt="">
图2 VQ-VAE数据流图</p> <p>结合 图1、图2 叙述其工作流程，下面基于采用了CIFAR10作为训练集情况下，各个数据结构描述。</p> <ol><li>输入x，其数据结构为[B,3,32,32]，，因此输入参数如此，B是batch的数量, 通道为3，图片长度宽度都是32像素；</li> <li>经过Encoder，得到 $Z_e( x )$, 其结构为 [B, C=D, H, W]，其中C是指编码器的Conv网络输出的Channels 的数量，而D是指矢量量化中矢量的维度，也就是后续查表（Embedding）所存储矢量的维度，另外，H,W表示输入图像经编码器处理后的长和宽，本例中，编码器输入是32 * 32，输出时为8 * 8，即H=8, W=8；</li> <li>将 $Z_e( x )$ 变形为 [B * H * W, D]，即每一个图片有 H*W 个编码，每个编码是D维，计算这些编码(B * H * W）与 Embedding 中 K 个矢量（在[3]中 K=512，表示矢量量化编码的矢量个数)之间的距离，通过最近邻算法构成如下映射：</li></ol> <p>$$
q(z=k|x) =
\begin{cases}
1 \ 如果k=argmin_j |Z_e(x) - e_j|^2\
0 \ 其它
\end{cases} \tag {1}
$$</p> <p>公式（1）表示当输入为 x 时，输出z = k 的概率是 ：
1）当 k 是矢量序列 { $e_1, e_2, ⋯ , e_K$ } 中与 $Z_e(x)$最近的矢量的下标时，条件概率为1；
2）否则为0。</p> <p>这里的矢量距离度量采用常见的欧拉距离，公式（1）便是最近邻算法的实现。
$$
z_q(x) = e_k \ 当k=argmin_i |Z_e(x) - e_j|^2 \tag{2}
$$</p> <p>公式（2）表示的是，通过最近邻计算出与 $Z_e( x ) 最近的矢量的下标为 k ，然后查表将 $e_k$ 输出作为编码输出 $z_q( x )。</p> <ol start="4"><li>$z_q(x)$ 作为Decoder的输入，有Decoder重建图像，输出 p(x∣z)</li></ol> <p>由上分析，我们得知VQ-VAE的输出的每一个编码都是离散的，它们是保存在 Embedding 中 K个矢量中的某一个。在[3]的实验中，一幅图片在矢量量化后，将由8 * 8 个 64 维矢量表示，而这里的每个矢量都是 Embedding 中512个矢量中的一个。
在整个实现中，有两个部分是很有特点的，其一就是上面讲的矢量量化过程，另外一个就是Loss的计算。在[1]中，Loss分为三个部分，如下：
$$
Loss = log p(x|z_q(x)) + |sg[Z_e(x)] - e|_2^2 + \beta|Z_e(x) - sg[e]|_2^2
$$
第一项 $log⁡ p(x∣z_q(x))$ 表示重构误差，这是二进制交叉熵的形式；第二项是用于update 在 Embedding中的字典项的Loss，其中 $sg[\cdot]$ 表示 stop gradient，即不执行后向梯度传递，因此，该项只对字典项（矢量量化中矢量）学习有效；第三项是对Encoder有效的Loss，其解释如下：</p> <p>由于 嵌入空间(the embedding space) 中的量是无量纲的，如果 $e_i$ 的训练速度跟不上encoder参数的训练速度的话，它就可能增大到任意值。因此，为使encoder能给出一个合理的embedding，于是就给encoder加上了一个惩罚项，其中 β  可选为 [ 0.1 , 2 ]，本例中选为β = 0.25 。</p> <p>我的理解是，如果encoder与embedding之间若无一个约束的话，则encoder的输出会严重偏离embedding中的矢量，</p> <p>另外，在backward时，重构误差梯度信息是直接传给Encoder的，但实际上Encoder的信息并不是直接被Decoder使用的，中间有Embedding转换一道，这是合理的吗？文章【1】给出的解释如下：</p> <p>这就是图2中红线标注出来的地方 $(∇_z L)$，因为Embedding最终输出的矢量维度与Encoder输出矢量的维度相同，而且相似，因此可认为梯度 $(∇_z L)$ 也可以改善Encoder的重构误差。这种说法虽然不严谨，但从实验结果上看，是行得通的。
小结一下Loss的作用对象：</p> <ol><li>Encoder 受 $log⁡ p(x∣z_q(x))  和 β ∥ Z_e(x) − sg[e]∥^2_2$  影响；</li> <li>Embedding 受 $log⁡ p(x∣z_q(x)) 和 ∥ sg[ Z_e(x) ] − e∥^2_2$ 影响；</li> <li>Decoder 受 $log p(x∣z_q(x))$。</li></ol> <h2 id="代码实现"><a href="#代码实现" class="header-anchor">#</a> 代码实现</h2> <p>完整的代码在[3]中，我们在这里就不一一详述了，只对一些有点特点的部分写一些注释。
我们先来看看 Embedding的实现：</p> <div class="language- extra-class"><pre class="language-text"><code>class VectorQuantizer(nn.Module):
    def __init__(self, num_embeddings, embedding_dim, commitment_cost):
        super(VectorQuantizer, self).__init__()
        
        self._embedding_dim = embedding_dim
        self._num_embeddings = num_embeddings
        
        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)
        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)
        self._commitment_cost = commitment_cost

    def forward(self, inputs):
        # convert inputs from BCHW -&gt; BHWC
        inputs = inputs.permute(0, 2, 3, 1).contiguous()
        input_shape = inputs.shape
        
        # Flatten input
        flat_input = inputs.view(-1, self._embedding_dim)
        
        # Calculate distances
        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) 
                    + torch.sum(self._embedding.weight**2, dim=1)
                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))
            
        # Encoding
        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)
        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings).to(device)
        encodings.scatter_(1, encoding_indices, 1)
        
        # Quantize and unflatten
        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)
        
        # Loss
        e_latent_loss = torch.mean((quantized.detach() - inputs)**2)
        q_latent_loss = torch.mean((quantized - inputs.detach())**2)
        loss = q_latent_loss + self._commitment_cost * e_latent_loss
        
        quantized = inputs + (quantized - inputs).detach()
        avg_probs = torch.mean(encodings, dim=0)
        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))
        
        # convert quantized from BHWC -&gt; BCHW
        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings
</code></pre></div><p>以下将就上述代码进行解读：</p> <ol><li>此处，Embedding通过 nn.Embedding 来实现，其中有 num_embeddings=512，embedding_dim = 64。对它的初始化，仅仅是通过uniform随机分布来设置初值。</li> <li>Encoder的输出是[ B * C * H * W ]，意味着一幅图片经 Encoder 提取的特征值是 [ C * H * W ]，将其整型为 [ H * W， C ] 即一幅图片有 H * W 个特征，每个特征的编码是 C 维。</li> <li>计算距离：</li></ol> <div class="language- extra-class"><pre class="language-text"><code>distances = (torch.sum(flat_input**2, dim=1, keepdim=True) + torch.sum(self._embedding.weight**2, dim=1) - 2 * torch.matmul(flat_input, self._embedding.weight.t()))

</code></pre></div><p>其实 torch.sum(flat_input2, dim=1, keepdim=True) 的维度与 torch.sum(self._embedding.weight2, dim=1) 的维度是不同的，前者是2048 * 1，而后者是 512*1，这样加的结果是 2048 * 512，即前者的每一个元素与后者的每一个元素相加得到的结果，得到一个2048 * 512矩阵，恰好与后面的 torch.matmul(flat_input, self._embedding.weight.t()) 维度相同。这里计算的是：
$$
|Z_e(x) - e_j|^2
$$</p> <p>接下来：</p> <div class="language- extra-class"><pre class="language-text"><code># Encoding
encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)
encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings).to(device)
encodings.scatter_(1, encoding_indices, 1)

</code></pre></div><p>这里是计算</p> <div class="language- extra-class"><pre class="language-text"><code>k = argmin_j|Z_e(x) -e_j|^2
</code></pre></div><p>由torch.argmin(distances, dim=1)获得每一个特征矢量对应的embedding矢量的索引值 k，再由它作为encoding_indices 将 1 分配到形如：[ B * H * W, K] 的矩阵上，其中 K 是embedding 字典中矢量的个数（即 num_embeddings） 。此 k 的形式（即 encodings 的形式）如下：
$$
q(z|x) =
\left[
\begin{matrix}
0 &amp; 0 &amp; 1 &amp;\cdots &amp; 0\
0 &amp; 1 &amp; 0 &amp;\cdots &amp; 0 \
\vdots &amp;\vdots &amp;\vdots &amp;\ddots &amp;\vdots \
0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0
\end{matrix}
\right]</p> <p>$$
EncodingIndices 矩阵共 B * H * W 行，每行有一个 1 其余皆为0， 矩阵共有 K 列，同1列上可以有多个1。
得到EncodingIndices 矩阵后，只需与Embedding矩阵相乘，便可以实现矢量量化的输出，如下：
$$
quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)
$$</p> <p>矩阵乘法 [B * H * W, K] * [ K, D] = [ B * H * W, D]，即：
$$
z_q(x) =
\left[
\begin{matrix}
0 &amp; 0 &amp; 1 &amp;\cdots &amp; 0\
0 &amp; 1 &amp; 0 &amp;\cdots &amp; 0 \
\vdots &amp;\vdots &amp;\vdots &amp;\ddots &amp;\vdots \
0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0
\end{matrix}
\right]</p> <ul><li>[e_1\ e_2\ \cdots e_K]^T \
=
\left[
\begin{matrix}
e_3\
e_2\
\vdots\
e_2
\end{matrix}
\right]</li></ul> <p>$$</p> <p>接下来是计算与 Embedding 相关的 Loss 计算：</p> <div class="language- extra-class"><pre class="language-text"><code># Loss
e_latent_loss = torch.mean((quantized.detach() - inputs)**2)
q_latent_loss = torch.mean((quantized - inputs.detach())**2)
loss = q_latent_loss + self._commitment_cost * e_latent_loss

</code></pre></div><p>这部分代码对应：
$$
|sg[Z_e(x)] - e|_2^2 + \beta|Z_e(x) - sg[e]|_2^2
$$
上式的 $sg[\cdot]$ 表示停止梯度（stop gradient），在实现时，我们看到用了Tensor.detach() 来实现，语法理解真是很精准，实现得很简练，这是佩服作者对Pytorch掌握的熟练，什么时候我才能也达到这个高度呢？</p> <p>至于其他部分的代码，还有值得学习的，但我在这里就不多说了，有兴趣的同学可以看看[3]，原滋原味。</p> <h2 id="小结"><a href="#小结" class="header-anchor">#</a> 小结：</h2> <p>VQ-VAE 通过离散的矢量对code进行量化和编码，压缩了编码空间，却达到可以媲美连续编码空间的重构效果，为图像的矢量化提供了一种可能的方法。</p> <h2 id="参考"><a href="#参考" class="header-anchor">#</a> 参考</h2> <p>[1] Neural Discrete Representation Learning, arXiv:1711.00937v2 [cs.LG] 30 May 2018
[2] Generating Diverse High-Fidelity Images with VQ-VAE-2，arXiv:1906.00446v1 [cs.LG] 2 Jun 2019
[3] https://github.com/zalandoresearch/pytorch-vq-vae
————————————————</p> <div class="language- extra-class"><pre><code>                        版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。
</code></pre></div><p>原文链接：https://blog.csdn.net/StreamRock/article/details/93881187</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/genmo/assets/js/app.26c693c1.js" defer></script><script src="/genmo/assets/js/2.778bb4ad.js" defer></script><script src="/genmo/assets/js/1.50b457b8.js" defer></script><script src="/genmo/assets/js/69.9e67f88e.js" defer></script>
  </body>
</html>
